{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea9b8691-ae95-4478-baad-788524f8e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D, AveragePooling2D,Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "#seed set to allow for reproducibility within the results\n",
    "seed = 2505\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "width = 83 #32#83  --16\n",
    "height= 83 #32#83  --16\n",
    "layers = 7 #7 sat #6 drone\n",
    "class_count = 5 #5\n",
    "input_shape = (width, height, layers)\n",
    "batch_size = 25 #25\n",
    "epochs = 100\n",
    "model_name = \"GullyDetector_tuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde8db05-f5ac-4f36-a526-b8e2dd227265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple CSV loader\n",
    "def load_samples(csv_file):\n",
    "    data = pd.read_csv(os.path.join(csv_file))\n",
    "    data = data[['FileName','Label','ClassName']]\n",
    "    file_names = list(data.iloc[:,0])\n",
    "    #Get labels withing second column\n",
    "    labels = list(data.iloc[:,1])\n",
    "    samples=[]\n",
    "    for samp,lab in zip(file_names,labels):\n",
    "        samples.append([samp,lab])\n",
    "    return samples\n",
    "\n",
    "#ensure size of tile is uniform\n",
    "def preprocessing(tile,label,class_count,layers,width,height):\n",
    "    #print(tile.shape,\"before\")\n",
    "    #to avoid artifacts, no antialiasing whn rescaling\n",
    "    tile = resize(tile, (layers,width,height),anti_aliasing=False)\n",
    "    #print(tile.shape,\"resize\")\n",
    "    #Returns the source array reshaped into the order expected by image processing and visualization software (matplotlib, scikit-image, etc) by swapping the axes order from (bands, rows, columns) to (rows, columns, bands)\n",
    "    tile = reshape_as_image(tile)\n",
    "    #print(tile.shape,\"reshape\")\n",
    "    \n",
    "    #normalising tile\n",
    "    tile = tile/255\n",
    "    \n",
    "    label = to_categorical(label,class_count)\n",
    "    return tile,label\n",
    "\n",
    "#Keras compatible data generator - works with rasterio compatible files (tiff only as written)\n",
    "def generator(samples,batch_size,width,height,layers,class_count):\n",
    "    \"\"\"\n",
    "    Yields next training batch, checks shape of tile, ensure image format - includes DEM\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        #shuffle(samples)\n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "\n",
    "            # For each example\n",
    "            for batch_sample in batch_samples:\n",
    "                # Load image (X) and label (y)\n",
    "                img_name = batch_sample[0]\n",
    "                label = batch_sample[1]\n",
    "                #load in file\n",
    "                #print(os.path.join(data_path,img_name))\n",
    "                with rasterio.open(os.path.join(img_name)) as ds:\n",
    "                    tile=ds.read()\n",
    "                #perform any preprocessing required\n",
    "                tile,label = preprocessing(tile,label,class_count,layers,width,height)     \n",
    "\n",
    "                # Add example to arrays\n",
    "                X_train.append(tile)\n",
    "                y_train.append(label)\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            #X_train = np.asarray(X_train).astype('float32')\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            # The generator-y part: yield the next training batch            \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edce11bb-27ae-4b54-af39-06daf94733d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gullydetector_CNN(input_shape,class_count,units,activation,dropout,lr):\n",
    "    #drop1 = dropout_rate, drop2 = dropout_rate_in\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation = activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout)) #0.25\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation = activation))\n",
    "    model.add(Dropout(dropout)) #0.25\n",
    "\n",
    "    model.add(Dense(class_count))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    #model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)\n",
    "    #opt = tensorflow.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740c2e2e-8194-49ca-8454-a9dd0b4d577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=64, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\",\"LeakyReLU\"]) #hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Choice(\"dropout\",values=[0.5, 0.6, 0.7,0.8])\n",
    "    lr = hp.Choice(\"lr\", values=[0.1, 0.01, 0.001, 0.0001,0.00001])\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = Gullydetector_CNN(\n",
    "        input_shape =input_shape,units=units, activation=activation, dropout=dropout, lr=lr,class_count = class_count\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147e3267-31a4-48c0-b77c-959d2aba8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'LeakyReLU'], 'ordered': False}\n",
      "dropout (Choice)\n",
      "{'default': 0.5, 'conditions': [], 'values': [0.5, 0.6, 0.7, 0.8], 'ordered': True}\n",
      "lr (Choice)\n",
      "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective= \"val_accuracy\",\n",
    "    overwrite=True,\n",
    "    directory=r\"./Tune\",\n",
    "    project_name=model_name,\n",
    "    max_epochs = 50,\n",
    "    factor = 3\n",
    ")\n",
    "\n",
    "#tuner = kt.RandomSearch(\n",
    "#    hypermodel=build_model,\n",
    "#    objective=\"val_accuracy\",\n",
    "#    max_trials=5,\n",
    "#    executions_per_trial=3,\n",
    "#    overwrite=True,\n",
    "#    directory=r\"./Tune\",\n",
    "#    project_name=model_name,\n",
    "#)\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21e834-a506-4238-bd1b-1d77b664b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 Complete [00h 39m 43s]\n",
      "val_accuracy: 0.7738271355628967\n",
      "\n",
      "Best val_accuracy So Far: 0.9525926113128662\n",
      "Total elapsed time: 1d 02h 54m 28s\n",
      "\n",
      "Search: Running Trial #56\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "384               |384               |units\n",
      "tanh              |relu              |activation\n",
      "0.8               |0.5               |dropout\n",
      "0.1               |1e-05             |lr\n",
      "6                 |50                |tuner/epochs\n",
      "0                 |17                |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |3                 |tuner/round\n",
      "\n",
      "Epoch 1/6\n",
      "1300/1300 [==============================] - 466s 358ms/step - loss: 9.7166 - accuracy: 0.7182 - val_loss: 60.4352 - val_accuracy: 0.2726\n",
      "Epoch 2/6\n",
      "1300/1300 [==============================] - 463s 356ms/step - loss: 10.7584 - accuracy: 0.7788 - val_loss: 17.4112 - val_accuracy: 0.6099\n",
      "Epoch 3/6\n",
      " 940/1300 [====================>.........] - ETA: 2:00 - loss: 11.0334 - accuracy: 0.7918"
     ]
    }
   ],
   "source": [
    "\n",
    "build_model(kt.HyperParameters())\n",
    "\n",
    "data_path = './Dataset'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "print ('the data list is: ',data_dir_list)\n",
    "fulldataset_df = load_samples('Full_drone_dataset.csv')\n",
    "\n",
    "train_df,test_df = train_test_split(fulldataset_df, test_size=0.2) #0.2\n",
    "test_df,valid_df = train_test_split(test_df, test_size=0.5)\n",
    "\n",
    "#counts necessary\n",
    "valid_count = len(valid_df)\n",
    "train_count = len(train_df)\n",
    "test_count = len(test_df)\n",
    "print(valid_count)\n",
    "print(train_count)\n",
    "print(test_count)\n",
    "\n",
    "#Create the generators \n",
    "train_datagen = generator(samples=train_df,batch_size=batch_size,width=width,height=height,layers=layers,class_count=class_count)\n",
    "test_datagen = generator(samples=test_df,batch_size=batch_size,width=width,height=height,layers=layers,class_count=class_count)\n",
    "valid_datagen = generator(samples=valid_df,batch_size=batch_size,width=width,height=height,layers=layers,class_count=class_count)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5,monitor='val_loss', verbose=1),\n",
    "    #ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    #ModelCheckpoint('model-inprogress-hyperparameter.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "]\n",
    "\n",
    "#history = model.fit(train_datagen,steps_per_epoch=train_count // batch_size, verbose=1, epochs=epochs,validation_data=valid_datagen,validation_steps=valid_count // batch_size,callbacks=callbacks)\n",
    "\n",
    "tuner.search(train_datagen,steps_per_epoch=train_count // batch_size,validation_steps=valid_count // batch_size, epochs=epochs, validation_data=valid_datagen,callbacks=callbacks,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79040c60-3d8e-4451-a352-2eaf8e2a314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open('tuning_modelsummary_Gullydetector5.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        tuner.results_summary()\n",
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d91b80-e7dd-433b-abcc-82ada5816b7d",
   "metadata": {},
   "source": [
    "from tensorflow import keras\n",
    "best_model = keras.models.load_model('StudyModel32_tuned1')\n",
    "\n",
    "best_model.build(input_shape=(None, 32, 32))\n",
    "best_model.summary()\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "with open('modelsummary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        best_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d2d112-963a-42bd-9f86-79e22be4c105",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the top 2 models.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#save model for later use\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuner' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "#save model for later use\n",
    "best_model.save(model_name + '1')\n",
    "\n",
    "best_model = models[1]\n",
    "#save model for later use\n",
    "best_model.save(model_name + '2')\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 32, 32))\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac23364-65b4-442b-995b-3a9e24563f35",
   "metadata": {},
   "source": [
    "dir_name = 'StudyModel32_tuned2'\n",
    "output_filename = dir_name\n",
    "import shutil\n",
    "shutil.make_archive(output_filename, 'zip', dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafd4cf-50ee-4d47-b181-23be986f03df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
